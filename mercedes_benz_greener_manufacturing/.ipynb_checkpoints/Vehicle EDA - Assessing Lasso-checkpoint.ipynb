{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import itertools\n",
    "from scipy.stats import skew\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from scipy.stats.stats import pearsonr\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import (LinearRegression, Ridge, Lasso, RandomizedLasso)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"input/train.csv\") # no missing data\n",
    "test = pd.read_csv(\"input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData = pd.get_dummies(train + test)\n",
    "train = allData[:len(train)]\n",
    "train = train.drop(\"ID\", axis=1)\n",
    "test = allData[len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X10</th>\n",
       "      <th>X100</th>\n",
       "      <th>X101</th>\n",
       "      <th>X102</th>\n",
       "      <th>X103</th>\n",
       "      <th>X104</th>\n",
       "      <th>X105</th>\n",
       "      <th>X106</th>\n",
       "      <th>X107</th>\n",
       "      <th>...</th>\n",
       "      <th>X8_yo</th>\n",
       "      <th>X8_yp</th>\n",
       "      <th>X8_yr</th>\n",
       "      <th>X8_ys</th>\n",
       "      <th>X8_yt</th>\n",
       "      <th>X8_yu</th>\n",
       "      <th>X8_yv</th>\n",
       "      <th>X8_yw</th>\n",
       "      <th>X8_yx</th>\n",
       "      <th>X8_yy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 2798 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID, X10, X100, X101, X102, X103, X104, X105, X106, X107, X108, X109, X11, X110, X111, X112, X113, X114, X115, X116, X117, X118, X119, X12, X120, X122, X123, X124, X125, X126, X127, X128, X129, X13, X130, X131, X132, X133, X134, X135, X136, X137, X138, X139, X14, X140, X141, X142, X143, X144, X145, X146, X147, X148, X15, X150, X151, X152, X153, X154, X155, X156, X157, X158, X159, X16, X160, X161, X162, X163, X164, X165, X166, X167, X168, X169, X17, X170, X171, X172, X173, X174, X175, X176, X177, X178, X179, X18, X180, X181, X182, X183, X184, X185, X186, X187, X189, X19, X190, X191, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 2798 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.11612161,  0.        , -0.28490583, ..., -0.2210006 ,\n",
       "        -0.15995248, -0.16834806],\n",
       "       [-0.11612161,  0.        , -0.28490583, ..., -0.2210006 ,\n",
       "        -0.15995248, -0.16834806],\n",
       "       [-0.11612161,  0.        , -0.28490583, ..., -0.2210006 ,\n",
       "         6.25185687, -0.16834806],\n",
       "       ..., \n",
       "       [-0.11612161,  0.        ,  3.50993166, ..., -0.2210006 ,\n",
       "        -0.15995248, -0.16834806],\n",
       "       [-0.11612161,  0.        , -0.28490583, ..., -0.2210006 ,\n",
       "        -0.15995248, -0.16834806],\n",
       "       [-0.11612161,  0.        , -0.28490583, ...,  4.52487456,\n",
       "        -0.15995248, -0.16834806]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-27c7b2b4cd0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Fit to the training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#predict on train set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# steps\n",
    "steps = [('scaler', StandardScaler()),\n",
    "         ('ridge', Ridge())]\n",
    "\n",
    "# Create the pipeline: pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Specify the hyperparameter space\n",
    "parameters = {'ridge__alpha':np.logspace(-4, 0, 50)}\n",
    "\n",
    "# Create the GridSearchCV object: cv\n",
    "cv = GridSearchCV(pipeline, parameters, cv=3)\n",
    "\n",
    "# Fit to the training set\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "#predict on train set\n",
    "y_pred_train=cv.predict(X_train)\n",
    "\n",
    "# Predict test set\n",
    "y_pred_test=cv.predict(X_test)\n",
    "\n",
    "# rmse on train set\n",
    "rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))\n",
    "\n",
    "# shape to export\n",
    "output=pd.concat([y_id, DataFrame(np.exp(y_pred_test)-1)], axis=1, ignore_index=True)\n",
    "output.columns=['Id', 'SalePrice']\n",
    "\n",
    "# export\n",
    "output.to_csv('./submission.csv', sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
